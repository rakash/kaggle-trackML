{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, 'other/')\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "from ipywidgets import FloatProgress,FloatText\n",
    "from IPython.display import display\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "import gc\n",
    "import cProfile\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline\n",
    "#make wider graphs\n",
    "sns.set(rc={'figure.figsize':(12,5)})\n",
    "plt.figure(figsize=(12,5))\n",
    "path='../data/LHC/train/'\n",
    "out_path='../data/LHC/clustered/'\n",
    "\n",
    "from functions.other import calc_features, get_event, score_event_fast, load_obj\n",
    "from functions.expand import *\n",
    "from functions.cluster import *\n",
    "from functions.ml_model import merge_with_probabilities,precision_and_recall,get_features,get_predictions\n",
    "\n",
    "# the following two lines are for changing imported functions, and not needing to restart kernel to use their updated version\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "Define parameters and run clustering, twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "00cff1de64d7a7f24df2e9430344f5ae90dc953c"
   },
   "outputs": [],
   "source": [
    "weights={'pi':1,'theta':0.15}\n",
    "stds={'z0':7.5, 'kt':7.5e-4}\n",
    "d =    {'sint':[225,110,110],\n",
    "        'cost':[225,110,110],\n",
    "          'phi':[550,260,260],\n",
    "        'min_group':[11,11,10],\n",
    "        'npoints':[250,1250,500]}\n",
    "filters=pd.DataFrame(d)\n",
    "nu=250\n",
    "\n",
    "def run_clustering(i):\n",
    "    event_num=1000+i\n",
    "    event_prefix = 'event00000{}'.format(event_num)\n",
    "    print('running '+event_prefix)\n",
    "    hits, cells, particles, truth = get_event(path,event_prefix)\n",
    "    history=[]\n",
    "\n",
    "    resa1=clustering(hits,stds,filters,phik=3.3,nu=nu)\n",
    "    resa1[\"event_id\"]=event_num-1000\n",
    "    score = score_event_fast(truth, resa1.rename(index=str, columns={\"label\": \"track_id\"}))\n",
    "    print(\"Your score: \", score)\n",
    "    resa1.to_csv(\"{}{}_cluster.csv\".format(out_path,event_prefix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [1:14:11<00:00, 44.52s/it]\n"
     ]
    }
   ],
   "source": [
    "### RUN PARALLEL \n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "res_list = Parallel(n_jobs=num_cores)(delayed(run_clustering)(i) for i in tqdm(range(100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
