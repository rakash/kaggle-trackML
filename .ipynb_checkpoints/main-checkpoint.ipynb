{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d01baac3757b22b92747599ed87524c1ddc0ad1d"
   },
   "source": [
    "# Chapter 1: Introduction\n",
    "\n",
    "The kernel demonstrates the clustering and expending we used to get to 7# place. Running this kernel on training event 1000 will score ~0.635 after the clustering stage, and 0.735 after expending stage.\n",
    "\n",
    "Every stage takes about 8-10 min on Kaggle, and about half the time on my laptop. In the clustering part of the kernel the algorithm uses 5.500 pairs of z0, 1/2R (more on it below). By increasing the number to about 100.000 pairs the score will plateau at about 0.765 (after expending).\n",
    "\n",
    "How does it work:\n",
    "In each clustering loop the algorithm try to find all tracks originating from (0,0,z0) and with a radius of 1/(2*kt).\n",
    "If a hit (x,y,z) is on a track the helix can be fully defined by the following features (1), (2)\n",
    "\n",
    "rr=(x^2+y^2)^0.5\n",
    "theta_=arctan(y/x)\n",
    "dtheta = arcsin(kt*rr)\n",
    "(1)\tTheta=theta_+dtheta\n",
    "(2)\t(z-z0)*kt/dtheta\n",
    "\n",
    "To solve the +pi,-pi problem we use sin, cos for theta.\n",
    "To make (2) more uniform, we use arctan((z-z0)/(3.3*dtheta/kt))\n",
    "\n",
    "After calculating the features, the algorithm tries to cluster all the hits with the same features. This is done by sparse binning – using np.unique.\n",
    "\n",
    "The disadvantage of sparse binning over dbscan is it’s sensitivity, the advantages are its speed and its sensitivity (almost no outliners).\n",
    "\n",
    "After clustering every hit choose if his cluster is good according to the clusters length.\n",
    "Every 500 loops all hits belonging to tracks which are long enough are removed from the dataset\n",
    "If two hits from the same detector are on the same track, the one which is closest to the track’s center of mass is chosen.\n",
    "The z0, kt pairs are chosen randomly. While running, the algorithm changes the bin width and the length of the minimum track to be extracted from the dataset.\n",
    "\n",
    "Expending is done by selecting the un-clustered hits which are close to the center of mass of the track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "02b47976a869d02bdf7ccaa72a67ffa6ace32d2c"
   },
   "source": [
    "# Chapter 2: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, 'other/')\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "from ipywidgets import FloatProgress,FloatText\n",
    "from IPython.display import display\n",
    "import time\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cluster import DBSCAN\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from itertools import product\n",
    "import gc\n",
    "import cProfile\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline\n",
    "#make wider graphs\n",
    "sns.set(rc={'figure.figsize':(12,5)})\n",
    "plt.figure(figsize=(12,5))\n",
    "path='files/'\n",
    "\n",
    "from functions.other import calc_features, get_event, score_event_fast\n",
    "from functions.expand import *\n",
    "from functions.cluster import *\n",
    "\n",
    "# the following two lines are for changing imported functions, and not needing to restart kernel to use their updated version\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9431ee1499c2628f7d1bba9d122ce510e1fc2d3a"
   },
   "source": [
    "Load train event 1000, which will be the event we will be working on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_num=0\n",
    "event_prefix = 'event00000100{}'.format(event_num)\n",
    "hits, cells, particles, truth = get_event(path,event_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "00cff1de64d7a7f24df2e9430344f5ae90dc953c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c08d1d0949d4441bcea07376a3690c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0, description='full score:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c3bd4538454c059574fa2906e794cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0, description='score:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53cb94eeb01414c820063b02b1b4ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0, description='s rate:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5ee3d0c8854017bacf988204c18183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0, description='add score:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa60933a4f254e898b90229b6af253d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=120939.0, description='Rest size:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1483258d096f47b2af15674d8a171e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=120939.0, description='Group size:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647eb03a18c4470f826e4cf17f3dfb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0, description='filter:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 230/300 [00:10<00:03, 22.44it/s]\n",
      "100%|██████████| 300/300 [00:13<00:00, 22.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 13.16945 sec\n",
      "Your score:  0.40190048140999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history=[]\n",
    "weights={'pi':1,'theta':0.15}\n",
    "stds={'z0':7.5, 'kt':7.5e-4}\n",
    "d =    {'sint':[225,110,110,110,110,110],\n",
    "        'cost':[225,110,110,110,110,110],\n",
    "          'phi':[550,260,260,260,260,260],\n",
    "        'min_group':[11,11,10,9,8,7],\n",
    "        'npoints':[50,50,50,50,50,50]}  # quick run for testing\n",
    "        #'npoints':[500,2000,1000,1000,500,500]}\n",
    "filters=pd.DataFrame(d)\n",
    "nu=500\n",
    "nu=50\n",
    "resa=clustering(hits,stds,filters,phik=3.3,nu=nu,truth=truth,history=history)\n",
    "resa[\"event_id\"]=event_num\n",
    "score = score_event_fast(truth, resa.rename(index=str, columns={\"label\": \"track_id\"}))\n",
    "print(\"Your score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4f21ab0aa074b244a682168403831e63a4bbdeaf"
   },
   "source": [
    "# Chapter 3: Expand tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f17bf5518006da909b788b04fd6646317b65dc9b"
   },
   "outputs": [],
   "source": [
    "mstd_vol={7:0,8:0,9:0,12:2,13:1,14:2,16:3,17:2,18:3}\n",
    "mstd_size=[4,4,4,4,3,3,3,2,2,2,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "weights={'theta':0.1, 'phi':1}\n",
    "nresa=expand_tracks(resa,hits,5,16,5,7,mstd=8,dstd=0.00085,phik=3.3,max_dtheta=0.9*np.pi/2,mstd_vol=mstd_vol,mstd_size=mstd_size,weights=weights,nhipo=100)\n",
    "nresa['event_id']=0\n",
    "score = score_event_fast(truth, nresa)\n",
    "print(\"Your score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "317879ec4824598fad62b7faba8f981eed065681"
   },
   "source": [
    "# Chapter 4: Employ Machine Learning\n",
    "## 4.1 General strategy\n",
    "- Produce different submission candidates sub_1, sub_2, ..., sub_N\n",
    "- Create a machine learning model, which gives probabilities between 0 and 1 for each track candidate\n",
    "- Merge two submission candidates by assigning to each hit the track, which has higher probability\n",
    "- Merge the submission candidates successively (sub_1 and sub_2 to sub_12, sub_12 and sub_3 to sub_123, etc.) to get the final submission\n",
    "\n",
    "[Note: For our final solution, the methods described in this chapter gave around +0.01 to the LB score. Certain benefits from these methods have already been captured by the function, which expands the tracks.]\n",
    "\n",
    "## 4.2 Create machine learning model (LightGBM)\n",
    "- Training data: Use the truth file of the 13 train events 3-15 to get true tracks (target=1). To get wrong tracks (target=0) use generated clustering submissions on those latter events. In particular, we consider each track candidate, for which not all hits belong to the same particle_id, as a wrong track. Also, choose only tracks which have at least length 4, to slightly optimize compute time at negligible cost.\n",
    "- Use 13 features per track: \n",
    " - variance of x,y,z (these are the most important)\n",
    " - minimum of x,y,z\n",
    " - maximum of x,y,z\n",
    " - mean of z\n",
    " - volume_id of first hit \n",
    " - number of clusters per track (i.e. are there many hits, which are close together)\n",
    " - number of hits / number of clusters   \n",
    "- Validation data: Same as with training data, but use the 3 training events 0,1,2\n",
    "\n",
    "[Note: We also tried many more features (compare below dataframe df_train), but they gave only small additional gains, so we just kept those 13 features for simplicity. In fact, many other interesting features, such as number of hits, number of different volumes crossed etc are closely related to the above used ones.]\n",
    "\n",
    "We have prepared the training and test data and load it directly from a pkl-file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5800822ec8d5798c6bc9ecba2df5f20964fe13cc"
   },
   "outputs": [],
   "source": [
    "df_train=load_obj('../input/trackml-validation-data-for-ml-pandas-df/df_train_v1.pkl')\n",
    "df_test=load_obj('../input/trackml-validation-data-for-ml-pandas-df/df_test_v1.pkl')\n",
    "y_train=df_train.target.values\n",
    "y_test=df_test.target.values\n",
    "print(\"The dataframe with all features:\")\n",
    "display(df_train.head())\n",
    "print(\"Features for each track:\",df_train.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "601fe0003c96bd293ef4dab881a52952bfc2e11c"
   },
   "source": [
    "In the competition, we used roughly 250 events for training, but the additional improvement to just using 13 events is not too big. We now create the LightGBM model, using the mentioned training data and features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d565ffb75b5d07695ee52de2830028a396133e1f"
   },
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "s=time.time()\n",
    "# choose which features of the tracks we want to use:\n",
    "columns=['svolume','nclusters', 'nhitspercluster', 'xmax','ymax','zmax', 'xmin','ymin','zmin', 'zmean', 'xvar','yvar','zvar']\n",
    "rounds=1000\n",
    "round_early_stop=50\n",
    "parameters = { 'subsample_for_bin':800, 'max_bin': 512, 'num_threads':8, \n",
    "               'application': 'binary','objective': 'binary','metric': 'auc','boosting': 'gbdt',\n",
    "               'num_leaves': 128,'feature_fraction': 0.7,'learning_rate': 0.05,'verbose': 0}\n",
    "train_data = lightgbm.Dataset(df_train[columns].values, label=y_train)\n",
    "test_data = lightgbm.Dataset(df_test[columns].values, label=y_test)\n",
    "model = lightgbm.train(parameters,train_data,valid_sets=test_data,num_boost_round=rounds,early_stopping_rounds=round_early_stop,verbose_eval=50)\n",
    "print('took',time.time()-s,'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b9a7d872c9ae35b65913ec0251262570119ecd6d"
   },
   "source": [
    "## 4.3 Judge machine learning model\n",
    "\n",
    "We doublecheck the model's performance, by calculating its precision, recall and accuracy on the validation set:\n",
    "\n",
    "[Note: For ML to be helpful in our situation, it needs to distinguish correct from wrong tracks with very high precision=true_positives/(false_positives+true_positives)). Also, it needs to do so for various sets of track candidates (especially such, which are generated if one tries to find tracks which originate far away from the origin; in those situations, often a lot of bad candidates are produced).]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e54c33c409e62e353b07f0ec981ad8cf8294a99f"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_test_pred=model.predict(df_test[columns].values)\n",
    "precision, recall, accuracy=precision_and_recall(y_test, y_test_pred,threshold=0.1)\n",
    "precision, recall, accuracy=precision_and_recall(y_test, y_test_pred,threshold=0.5)\n",
    "precision, recall, accuracy=precision_and_recall(y_test, y_test_pred,threshold=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4fa41aa28075d5242c5aa1b6e054cfcdf5b83554"
   },
   "source": [
    "## 4.4 Use machine learning model\n",
    "\n",
    "Let us first load the event data of training event 0, as well as two generated submissions we have prepared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ce743814da42e4100c9b95f51b61695f3d5669b"
   },
   "outputs": [],
   "source": [
    "### create one more submission\n",
    "history=[]\n",
    "resa2=clustering(hits,stds,filters,phik=3.3,nu=nu,truth=truth,history=history)\n",
    "resa2[\"event_id\"]=event_num\n",
    "score = score_event_fast(truth, resa2.rename(index=str, columns={\"label\": \"track_id\"}))\n",
    "print(\"Your score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4fdc58c29b9f606784e994d7d4afd0ca81bd0b4d"
   },
   "source": [
    "Calculate the probabilities for the tracks in those two submissions (small optimization: take also length of track into account, and after a couple of merged submissions, ask the probability of the track from the new submission to be at least C higher than the current probability; this latter option is not used in this kernel, but was used when merging >= 4 submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db72968ce0c1f3b4ed017ffed2d466196bfdf2f6"
   },
   "outputs": [],
   "source": [
    "\n",
    "preds={}\n",
    "preds[0]=get_predictions(resa,hits,model)\n",
    "preds[1]=get_predictions(resa2,hits,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21bd16948d31e9f241a38d1db245373e1c04d6d0"
   },
   "source": [
    "Merge both submissions, based on the probabilities of its track candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8443e1cee886104592ca4c8e685cc358b8e4cf73"
   },
   "outputs": [],
   "source": [
    "print('Merge submission 0 and 1 into sub01:')\n",
    "sub01=merge_with_probabilities(resa,resa2,preds[0],preds[1],truth,length_factor=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "395162bb52a0a5707cf36045e348a5a7d13ee3fe"
   },
   "source": [
    "To continue, take additional submission sub2 and merge it onto sub01. Therefore, need to first calculcate probabilities of the tracks in sub01, as well as sub2. Similarly for more submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c2c9f2d927c90e1fe456e501a29b4b8efb2b8fb"
   },
   "outputs": [],
   "source": [
    "# Expanding the merged submission of the two clustering solutions gives:\n",
    "mstd_vol={7:0,8:0,9:0,12:2,13:1,14:2,16:3,17:2,18:3}\n",
    "mstd_size=[4,4,4,4,3,3,3,2,2,2,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "weights={'theta':0.1, 'phi':1}\n",
    "nresa2=expand_tracks(sub01,hits,5,16,5,7,mstd=8,dstd=0.00085,phik=3.3,max_dtheta=0.9*np.pi/2,mstd_vol=mstd_vol,mstd_size=mstd_size,weights=weights,nhipo=100)\n",
    "nresa2['event_id']=0\n",
    "score = score_event_fast(truth, nresa2)\n",
    "print(\"Your score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c39095d074959c9b68c95fc3b5e35cc65811611b"
   },
   "source": [
    "We achieved 0.757, which is a +0.02 improvement in the case of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28ef848473a3793eb39a7e4c4b3d010148d6708e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
