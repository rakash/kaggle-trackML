{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used to create training files\n",
    "Before running this notebook you will need to run the solution algorithm on the training files and save the solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.cluster.dbscan_ import dbscan\n",
    "import sys\n",
    "sys.path.insert(0, 'other/')\n",
    "from trackml.dataset import load_dataset\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from functions.other import calc_features, get_event, score_event_fast, load_obj,hit_score\n",
    "from functions.expand import *\n",
    "from functions.cluster import *\n",
    "from functions.ml_model import merge_with_probabilities,precision_and_recall,get_features,get_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_hits=4\n",
    "train_path='../data/LHC/train/'    #Path to traning data\n",
    "clustered_path = '../data/LHC/clustered/' #path to solutions\n",
    "solution_prefix = '_cluster' #the solution files prefix\n",
    "num_train=25\n",
    "num_val=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, filename):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "        filename = \"folder/filename.pkl\n",
    "        arr = [3,4,5]\n",
    "        save_obj(arr ,filename)\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"saved to \" + filename)\n",
    "\n",
    "\n",
    "def load_obj(filename):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "        filename = \"folder/filename.pkl\n",
    "        arr = load_obj(arr ,filename)\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        print(\"loaded from \" + filename)\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def get_true_tracks(hits,particles,truth):\n",
    "    hitst=hits.merge(truth[['hit_id','particle_id']],on='hit_id',how='left')\n",
    "    hitst=hitst.merge(particles[['particle_id','nhits']],on='particle_id',how='left')\n",
    "    hitst=hitst[hitst.nhits>=min_hits].rename(columns={'particle_id':'track_id'})\n",
    "    d=get_features(hitst)\n",
    "    return d[['svolume','nclusters','nhitspercluster','xmax','ymax','zmax','xmin','ymin','zmin','zmean','xvar','yvar','zvar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do event event000001000\n",
      "true:3252\n",
      "wrong:3087\n",
      "do event event000001001\n",
      "true:2379\n",
      "wrong:1922\n",
      "do event event000001002\n",
      "true:3383\n",
      "wrong:3290\n",
      "do event event000001003\n",
      "true:2737\n",
      "wrong:2404\n",
      "do event event000001004\n",
      "true:3773\n",
      "wrong:3888\n",
      "do event event000001005\n",
      "true:2889\n",
      "wrong:2632\n",
      "do event event000001006\n",
      "true:3151\n",
      "wrong:2876\n",
      "do event event000001007\n",
      "true:2927\n",
      "wrong:2644\n",
      "do event event000001008\n",
      "true:2952\n",
      "wrong:2735\n",
      "do event event000001009\n",
      "true:2846\n",
      "wrong:2540\n",
      "do event event000001010\n",
      "true:2695\n",
      "wrong:2480\n",
      "do event event000001011\n",
      "true:3109\n",
      "wrong:2920\n",
      "do event event000001012\n",
      "true:2900\n",
      "wrong:2511\n",
      "do event event000001013\n",
      "true:2775\n",
      "wrong:2503\n",
      "do event event000001014\n",
      "true:3372\n",
      "wrong:3337\n",
      "do event event000001015\n",
      "true:3280\n",
      "wrong:3177\n",
      "do event event000001016\n",
      "true:3130\n",
      "wrong:2881\n",
      "do event event000001017\n",
      "true:3318\n",
      "wrong:3226\n",
      "do event event000001018\n",
      "true:2329\n",
      "wrong:1911\n",
      "do event event000001019\n",
      "true:3285\n",
      "wrong:3215\n",
      "do event event000001020\n",
      "true:2400\n",
      "wrong:1970\n",
      "do event event000001021\n",
      "true:2716\n",
      "wrong:2450\n",
      "do event event000001022\n",
      "true:2711\n",
      "wrong:2384\n",
      "do event event000001023\n",
      "true:3453\n",
      "wrong:3378\n",
      "do event event000001024\n",
      "true:3089\n",
      "wrong:2890\n",
      "do event event000001025\n",
      "true:3194\n",
      "wrong:3123\n",
      "do event event000001026\n",
      "true:3283\n",
      "wrong:3273\n",
      "do event event000001027\n",
      "true:3081\n",
      "wrong:2829\n",
      "do event event000001028\n",
      "true:3087\n",
      "wrong:2930\n",
      "do event event000001029\n",
      "true:2852\n",
      "wrong:2527\n",
      "saved to files/df_train_v2-reduced.pkl\n",
      "saved to files/df_test_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "df_all_subs=pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in range(0,num_train+num_val):\n",
    "    event='event000001{:03d}'.format(i)\n",
    "    print('do event',event)\n",
    "    hits, cells, particles, truth = get_event(train_path,event)\n",
    "    sub=pd.read_csv('{}{}{}.csv'.format(clustered_path,event,solution_prefix),index_col=False)\n",
    "    ssub=hit_score(sub,truth)\n",
    "    gp=ssub.groupby('track_id').agg({'score':'sum','weight':'sum','track_len':'max'}).reset_index()\n",
    "    ssub=ssub[['hit_id','track_id']].merge(gp,on='track_id',how='left')\n",
    "    ssub=ssub[((ssub.score==0) | (ssub.score<ssub.weight)) & (ssub.track_len>4)][['hit_id','track_id']]\n",
    "    ssub=ssub.merge(hits,on='hit_id',how='left')\n",
    "    df_wrong=get_features(ssub)\n",
    "    df_wrong=df_wrong[['svolume','nclusters','nhitspercluster','xmax','ymax','zmax','xmin','ymin','zmin','zmean','xvar','yvar','zvar']]\n",
    "\n",
    "    #todo 1: Select all WRONG tracks as follows. Take tracks, which: \n",
    "    #      (1) have at least 4 hits, and at most 23 hits\n",
    "    #      (2) not all hits belong to the same particle_id (eg by merging the particle_id onto the \n",
    "             # the submission dataframe, then count how many unique particle_ids each track has and only\n",
    "             # consider those that have >= particle_ids\n",
    "    \n",
    "    #todo 2: Create a dataframe df_wrong, such that each row in this dataframe is one track. In addition\n",
    "    #        add all features of this track (which will be used later in the ML algorithm). Each feature\n",
    "    #        is one column\n",
    "    df_wrong['target']=0\n",
    "    df_true=get_true_tracks(hits,particles,truth)\n",
    "    df_true['target']=1\n",
    "    df_true=df_true.sample(frac=0.35) #We want the num of true events==the num of wrong events\n",
    "    print('true:{}'.format(df_true.shape[0]))\n",
    "    print('wrong:{}'.format(df_wrong.shape[0]))\n",
    "    df_both=pd.concat([df_true,df_wrong],ignore_index=False,sort=True)\n",
    "    df_both['event_id']=i\n",
    "    df_both=df_both.sample(frac=1).reset_index(drop=True)  # shuffle\n",
    "    df_all_subs=df_all_subs.append(df_both\t, ignore_index=True)\n",
    "\n",
    "\n",
    "df_train=df_all_subs[df_all_subs['event_id']>num_val]\n",
    "df_test=df_all_subs[df_all_subs['event_id']<=num_val]\n",
    "    \n",
    "save_obj(df_train,'files/df_train_v2-reduced.pkl')\n",
    "save_obj(df_test,'files/df_test_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
